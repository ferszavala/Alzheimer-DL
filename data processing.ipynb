{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d21d958e",
   "metadata": {},
   "source": [
    "The aim is to pass the images that we have to tensors, to be able to work later with a convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4727ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch # an open source ML library used for creating neural networks\n",
    "from torch.utils.data import Dataset \n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import R2Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f06d4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in e:\\miniconda3\\envs\\ai\\lib\\site-packages (0.9.3)\n",
      "Requirement already satisfied: torch>=1.3.1 in e:\\miniconda3\\envs\\ai\\lib\\site-packages (from torchmetrics) (2.0.0.dev20230219+cu117)\n",
      "Requirement already satisfied: packaging in e:\\miniconda3\\envs\\ai\\lib\\site-packages (from torchmetrics) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in e:\\miniconda3\\envs\\ai\\lib\\site-packages (from torchmetrics) (1.24.2)\n",
      "Requirement already satisfied: filelock in e:\\miniconda3\\envs\\ai\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in e:\\miniconda3\\envs\\ai\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: networkx in e:\\miniconda3\\envs\\ai\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (3.0rc1)\n",
      "Requirement already satisfied: sympy in e:\\miniconda3\\envs\\ai\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (1.11.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\miniconda3\\envs\\ai\\lib\\site-packages (from sympy->torch>=1.3.1->torchmetrics) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (e:\\miniconda3\\envs\\ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\miniconda3\\envs\\ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\miniconda3\\envs\\ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\miniconda3\\envs\\ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\miniconda3\\envs\\ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (e:\\miniconda3\\envs\\ai\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# More imports\n",
    "from torchvision.datasets import ImageFolder # to load the dataset\n",
    "from torchvision import transforms # to transform the dataset (the images) \n",
    "\n",
    "import pytorch_lightning as pl  # to help to write more scalable and maintainable code\n",
    "import torchmetrics #for evaluating and reporting metrics\n",
    "\n",
    "# install torchmetrics\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e75adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(path='archive/OriginalDataset', RNN=False):\n",
    "    dataset = ImageFolder(root=path)\n",
    "    transform1 = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # resize the image to 128x128\n",
    "        transforms.ToTensor(),  # convert the image to a tensor\n",
    "        # normalize the image with the mean and standard deviation of the ImageNet dataset\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "        transforms.Grayscale(num_output_channels=1) if RNN else transforms.Lambda(lambda x: x)\n",
    "    ])\n",
    "    dataset = ImageFolder(root='archive/OriginalDataset', transform=transform1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b44519e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of the first data point shown as an image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "165ac4bd",
   "metadata": {},
   "source": [
    "Once the data is organized correctly and the images have been converted to tensors, it is time to implement a CNN network with four classes (it uses three Conv2-ReLu-MaxPool layers and one sequential one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b93f58f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple cnn model with 4 classes\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN,self).__init__()\n",
    "        self.cnn = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128 * 16 * 16, 4),\n",
    "            torch.nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff4db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ImageRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "\n",
    "        # Reshape the input tensor to a 2D sequence\n",
    "        x = x.view(batch_size, channels, -1)\n",
    "\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e438cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PLModel(pl.LightningModule):    \n",
    "    def __init__(self,model, num_classes):\n",
    "        super(PLModel,self).__init__()\n",
    "        self.model = model\n",
    "        self.accuracy = torchmetrics.Accuracy('multiclass', num_classes=num_classes)\n",
    "        self.loss  = torch.nn.functional.cross_entropy      \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)        \n",
    "        self.log('train_accuracy', self.accuracy(y_hat, y), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)        \n",
    "        self.log('val_accuracy', self.accuracy(y_hat, y), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10fdbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, Dataset, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.Dataset = Dataset\n",
    "        self.batch_size = batch_size\n",
    "    def setup(self, stage=None):\n",
    "        # split dataset into train, val, test\n",
    "        dataset = self.Dataset\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        val_size = int(0.1 * len(dataset))\n",
    "        test_size = len(dataset) - train_size - val_size\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d22d2e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type     | Params\n",
      "--------------------------------------\n",
      "0 | model    | ImageRNN | 2.1 M \n",
      "1 | accuracy | Accuracy | 0     \n",
      "--------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.457     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb7809c76c84a1d995cc7c3839bd2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b1519795cc45b7adf3a6b21163b1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11425774b2934436ae6c88234ede19e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "dataset = getData(RNN=True)\n",
    "dataset = DataModule(dataset, batch_size=32)\n",
    "m = ImageRNN(16384, 128, 4)\n",
    "model = PLModel(m, 4)\n",
    "\n",
    "trainer = pl.Trainer(accelerator = \"gpu\", max_epochs=10) # use GPU, 10 epochs\n",
    "\n",
    "\n",
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4035d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type      | Params\n",
      "---------------------------------------\n",
      "0 | model    | SimpleCNN | 224 K \n",
      "1 | accuracy | Accuracy  | 0     \n",
      "---------------------------------------\n",
      "224 K     Trainable params\n",
      "0         Non-trainable params\n",
      "224 K     Total params\n",
      "0.897     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b338c0602a3f4b3fb11f768ecc21c080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9794d38bd52c449f966d811f3030938e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model\n",
    "m = SimpleCNN()\n",
    "dataset = getData()\n",
    "dataset = DataModule(dataset, batch_size=32)\n",
    "model = PLModel(m, 4)\n",
    "\n",
    "trainer = pl.Trainer(accelerator = \"gpu\", max_epochs=10) # use GPU, 10 epochs\n",
    "\n",
    "\n",
    "trainer.fit(model,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38fd0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.resnet = torch.hub.load(\n",
    "            'pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "\n",
    "        self.resnet.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d169421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\franz/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type     | Params\n",
      "--------------------------------------\n",
      "0 | model    | Resnet   | 11.2 M\n",
      "1 | accuracy | Accuracy | 0     \n",
      "--------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.714    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d80fd0722e647cfbe590d13f7d47114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "e:\\miniconda3\\envs\\AI\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab1c706b3d74fceab0e8b3129d0ced4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39eea28c84a547e8bb2805e46a5e8d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd0be0aead94532ad9104b7558f61dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3211aa63504030986455fdd6f7aa46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15e5b44c2ac479e8a03b118d7b130d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = Resnet()\n",
    "dataset = getData()\n",
    "model = PLModel(m, 4)\n",
    "dataset = DataModule(dataset, batch_size=32)\n",
    "\n",
    "trainer = pl.Trainer(accelerator = \"gpu\", max_epochs=10) # use GPU, 10 epochs\n",
    "\n",
    "\n",
    "trainer.fit(model,dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
